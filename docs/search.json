[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Al Marj Flood Impact Comprehensive Evaluation System",
    "section": "",
    "text": "This project crafts an application within Google Earth Engine to evaluate the repercussions of the substantial flood event that transpired in Al Marj, Libya, during September 2023. The application integrates satellite imagery for flood mapping, land cover data for analyzing affected land cover types, and random forest classification to detect affected buildings. Additionally, it utilizes population grid data to estimate the number of people affected by the flood. The results provide a comprehensive assessment of the flood extent, affected land cover areas, impacted buildings, and the affected population, which is crucial for informing disaster response and management efforts.\n\n\n\nStudy Area\n\n\n\n\nIn September 2023, severe flooding in Al Marj, Libya, caused significant damage to infrastructure and displaced numerous people. Rapid and accurate assessment of the flood’s impact is essential for effective disaster response and management. This application aims to address the following key research questions:\n\nWhat is the total area affected by the flooding?\nWhat is the extent of damage affected by the flooding to different land cover types, particularly agricultural land and built-up areas? How the the flooding affact the area of Buildings?\nHow many people are estimated to be affected by the flooding?\n\n\n\n\nGovernment departments and international organizations:\nBy visualizing flooded areas, affected buildings, and population data, our project enables these departments to quickly and accurately assess the disaster situation. This facilitates effective rescue and reconstruction planning, as well as optimization of future urban development, land use, and drainage systems.\nAffected communities and the public:\nThe spatial distribution map of the flooded area generated by the project can help the affected communities and the public intuitively understand the scope and severity of the flood impact, and take timely countermeasures.\n\n\n\nSentinel-1 Satellite Image: Sentinel-1 collects C-band synthetic aperture radar (SAR) imagery at a variety of polarizations and resolutions. We use it to detect flood coverage.\nSentinel-2 Satellite Image: Sentinel-2 is a wide-swath, high-resolution, multispectral imaging mission with a global 5-day revisit frequency.\nSurface Water:JRC Global Surface Water Metadata contains maps of the location and temporal distribution of surface water. Year-round water is filtered using the JRC Global Water Seasonal Data layer.\nDEM:WWF HydroSHEDS Void-Filled DEM excludes areas with gradients greater than 5%.\nLand Classification: ESA WorldCover 10m v200 ESA WorldCover10m contains 11 land cover classes based on Sentinel-1 and Sentinel-2 data.\nPopulation: GHSL: Global population surfaces 1975-2030 contains the spatial distribution of residential population, expressed as the absolute number of inhabitants of the cell.\n\n\n\nFlood extent mapping:\nThe areas affected by the flood are identified by calculating the difference between pre-flood and post-flood images.\nLand cover impact assessment: By overlaying the flood extent layer with the land cover, the affected built-up areas and croplands are assessed.\nBuilding damage assessment:\nThe random forest classification algorithm is applied to the Sentinel-2 multispectral imagery to extract buildings within the built-up areas. The accuracy is evaluated using a confusion matrix.\nPopulation impact assessment:\nBy overlaying the flood extent map with the population grid, the application calculates the total number of individuals residing within the inundated areas.\n\n\n\nProcedure\n\n\n\n\n\nUsers will be able to interact with the perform:\n\nDraw an Area of Interest (AOI): Users can draw a polygon on the map to define a specific area they want to analyze.\nObtain information: The application will process the data within the AOI and display the key indicators in the results panel, including Total Area, Flood Extent Areas, Damaged Built-Up Areas, Damaged Cropland Areas, Estimated Affected Population.\nVisualization: The map will display visual overlays within the AOI that include Affected Built-Up, Affected Cropland, A ffected Building Footprints, and Flood Areas. This setup clearly identifies flood-impacted regions.\n\n\n\n\nInterface\n\n\n\n\n\n\nThis is our Earth Engine application.\n\n\n\n\n\n\n\n\n\n1. Flood Area Analysis\n1.1 Data Preprocessing\nWe imported the administrative boundary data of Al Marj region and filtered the area of interest (AOI).\n// Import the administrative boundary of Libya and filter the target region (Al Marj) as the area of interest (AOI)\nvar admin = ee.FeatureCollection(\"projects/ee-hanmengyuan9/assets/libya\");\nvar geometry = admin.filter(ee.Filter.eq('shapeName', 'Al Marj'));\nMap.addLayer(geometry, {color: 'grey'}, 'Al Marj');\nAnd we selected the Sentinel-1 SAR image collection, set parameters and filter images for the flood periods.\n// Define the time periods before and after the flood event\nvar before_start = '2023-09-01';\nvar before_end = '2023-09-15';\nvar after_start = '2023-09-23';\nvar after_end = '2023-09-30';\n\n// Set sensor parameters for the satellite data collection\nvar polarization = (\"VH\", \"VV\");\nvar pass_direction = \"DESCENDING\";\nvar difference_threshold = 1.00; \n\n// Defining the area of interest based on the filtered geometry\nvar aoi = geometry;\n\n// Filtering the satellite image collection based on the specified parameters\nvar collection = ee.ImageCollection('COPERNICUS/S1_GRD')\n  .filter(ee.Filter.eq('instrumentMode', 'IW'))\n  .filter(ee.Filter.listContains('transmitterReceiverPolarisation', polarization))\n  .filter(ee.Filter.eq('orbitProperties_pass', pass_direction))\n  .filter(ee.Filter.eq('resolution_meters', 10))\n  .filterBounds(aoi)\n  .select(polarization);\n  \n// Filter the image collection to obtain images from before and after the flood\nvar before_collection = collection.filterDate(before_start, before_end);\nvar after_collection = collection.filterDate(after_start, after_end);\nThen, we mosaicked, clipped, and applied speckle noise reduction to the filtered before and after image collections to optimize data quality.\n// Create a mosaic of selected tiles and clip to study area\nvar before = before_collection.mosaic().clip(aoi);\nvar after = after_collection.mosaic().clip(aoi);\n\n// Apply reduce the radar speckle by smoothing  \nvar smoothing_radius = 50;\nvar before_filtered = before.focal_mean(smoothing_radius, 'circle', 'meters');\nvar after_filtered = after.focal_mean(smoothing_radius, 'circle', 'meters');\n1.2 Flood Extent Extraction\nWe extracted the flood extent using threshold segmentation and further optimize the flood extent using surface water data, connectivity analysis, and terrain filtering.\n// Calculate the difference between the before and after images\nvar difference = after_filtered.divide(before_filtered);\n\n// Apply the predefined difference-threshold and create the flood extent mask \nvar threshold = difference_threshold;\nvar difference_binary = difference.gt(threshold);\n\n// Refine flood result using additional datasets\n      \n      // Include JRC layer on surface water seasonality to mask flood pixels from areas\n      // of \"permanent\" water (where there is water &gt; 10 months of the year)\n      var swater = ee.Image('JRC/GSW1_0/GlobalSurfaceWater').select('seasonality');\n      var swater_mask = swater.gte(10).updateMask(swater.gte(10));\n      \n      // Flooded layer where perennial water bodies (water &gt; 10 mo/yr) is assigned a 0 value\n      var flooded_mask = difference_binary.where(swater_mask,0);\n      // final flooded area without pixels in perennial waterbodies\n      var flooded = flooded_mask.updateMask(flooded_mask);\n      \n      // Compute connectivity of pixels to eliminate those connected to 8 or fewer neighbours\n      // This operation reduces noise of the flood extent product \n      var connections = flooded.connectedPixelCount();    \n      var flooded = flooded.updateMask(connections.gte(8));\n      \n      // Mask out areas with more than 5 percent slope using a Digital Elevation Model \n      var DEM = ee.Image('WWF/HydroSHEDS/03VFDEM');\n      var terrain = ee.Algorithms.Terrain(DEM);\n      var slope = terrain.select('slope');\n      var flooded = flooded.updateMask(slope.lt(5));\n1.3 Flood Area Calculation\nWe calculated the flood inundation area based on pixel area and regional statistics.\n// Calculate flood extent area\n// Create a raster layer containing the area information of each pixel \nvar flood_pixelarea = flooded.select(polarization)\n  .multiply(ee.Image.pixelArea());\n\n// Sum the areas of flooded pixels\n// default is set to 'bestEffort: true' in order to reduce computation time, for a more \n// accurate result set bestEffort to false and increase 'maxPixels'. \nvar flood_stats = flood_pixelarea.reduceRegion({\n  reducer: ee.Reducer.sum(),              \n  geometry: aoi,\n  scale: 10, // native resolution \n  //maxPixels: 1e9,\n  bestEffort: true\n  });\n\n// Convert the flood extent to hectares (area calculations are originally given in meters)  \nvar flood_area_ha = flood_stats\n  .getNumber(polarization)\n  .divide(10000)\n  .round();\n\n\n\nFlooded Area\n\n\n2. Identify buildings affected by flooding\n2.1 Data preprocessing\nThe obtained Sentinel-2 image is filtered, processed, cropped, and a preliminary image is generated. A mask is then applied to the data based on NDWI and NDVI thresholds (0.3 and 0.2, respectively) to filter out non-water and low vegetation cover areas.\n// Define an array of band names for Sentinel-2 imagery\nvar bands = ['B2', 'B3', 'B4', 'B5', 'B6', 'B7', 'B8', 'B8A', 'B11', 'B12'];\n\n// Create an ImageCollection of Sentinel-2 surface reflectance images\nvar sentinel2 = ee.ImageCollection('COPERNICUS/S2_SR')\n  .filter(ee.Filter.date(before_start, after_end)) // Filter images by date range\n  .filter(ee.Filter.lt('CLOUDY_PIXEL_PERCENTAGE', 10)) // Filter images with less than 10% cloud cover\n  .mean() // Compute the mean value of each pixel across the filtered images\n  .select(bands) // Select the specified bands\n  .clip(geometry); // Clip the resulting image to the specified geometry\n\n// Define visualization parameters for RGB composite\nvar s_rgb = {\n  min: 0.0, // Minimum value for stretching the image\n  max: 3000, // Maximum value for stretching the image\n  bands: ['B4', 'B3', 'B2'], // Red, Green, Blue bands for the composite\n  opacity: 1 // Opacity of the layer\n};\n\n// Calculate NDVI (Normalized Difference Vegetation Index)\nvar ndvi = sentinel2.normalizedDifference(['B8', 'B4']).select(['nd'], ['ndvi']);\n\n// Calculate NDWI (Normalized Difference Water Index)\nvar ndwi = sentinel2.normalizedDifference(['B3', 'B8']).select(['nd'], ['ndwi']);\n\n// Create a masked image based on NDWI and NDVI thresholds and add NDVI band\nvar image = sentinel2\n  .updateMask(ndwi.lt(0.3)) // Mask pixels with NDWI less than 0.3\n  .updateMask(ndvi.lt(0.2)) // Mask pixels with NDVI less than 0.2\n  .addBands(ndvi); // Add the NDVI band to the image\n2.2 RF analysis\nTo improve the accuracy of the training building model, we will classify and identify different features (such as buildings, farmland, deserts, etc.) together by Random Forest.\nvar building_points = ee.FeatureCollection.randomPoints(buildings2, 3000).map(function(i) {\n  return i.set({'class': 0});\n});\nvar farm_points = ee.FeatureCollection.randomPoints(farmland, 3000).map(function(i) {\n  return i.set({'class': 1});\n});\nvar desert_points = ee.FeatureCollection.randomPoints(desert, 3000).map(function(i) {\n  return i.set({'class': 2});\n});\nvar water_points = ee.FeatureCollection.randomPoints(water, 3000).map(function(i) {\n  return i.set({'class': 3});\n});\nvar road_points = ee.FeatureCollection.randomPoints(road, 3000).map(function(i) {\n  return i.set({'class': 4});\n});\nvar parking_points = ee.FeatureCollection.randomPoints(parking, 3000).map(function(i) {\n  return i.set({'class': 5});\n});\nCombine the random points and split them into training and validation sets and we used the split ratio equal to 0.7.\n// Combine the random points for each land cover class into a single FeatureCollection\nvar sample = ee.FeatureCollection([\n  building_points,\n  farm_points,\n  desert_points,\n  water_points,\n  road_points,\n  parking_points\n])\n.flatten()  // Flatten the FeatureCollection\n.randomColumn(); // Add a random column to the FeatureCollection for splitting\n\n// Define the split ratio for training and validation samples\nvar split = 0.7;\n\n// Create training sample by filtering the sample FeatureCollection where the random column is less than the split ratio\nvar training_sample = sample.filter(ee.Filter.lt('random', split));\n\n// Create validation sample by filtering the sample FeatureCollection where the random column is greater than or equal to the split ratio\nvar validation_sample = sample.filter(ee.Filter.gte('random', split));\nSample the image using the training and validation points and Train a Random Forest classifier using the training samples.\n// Sample the image using the training sample\nvar training = image.sampleRegions({\n  collection: training_sample,\n  properties: ['class'],\n  scale: 10,\n});\n\n// Sample the image using the validation sample\nvar validation = image.sampleRegions({\n  collection: validation_sample,\n  properties: ['class'],\n  scale: 10\n});\n\n// Train a Random Forest classifier using the training samples\nvar model = ee.Classifier.smileRandomForest(400)\n  .train(training, 'class');\nClassify the image using the trained model and extract the building class from the prediction.\n// Classify the image using the trained model\nvar prediction = image.classify(model);\n\n// Extract the building class from the prediction by masking pixels that are not classified as buildings (class 0)\nvar building_prediction = prediction.updateMask(prediction.eq(0));\n3.Calculate the built-up areas, croplands, buildings footprint and population after the disaster\nImport ESA WorldCover into the map and extract cropland and built-up land from it. By intersecting the Build-up land with the identified buildings, we will focus on the disaster situation of the buildings in the built-up area. Finally, the flood data mask was used to obtain the cropland, built-up areas, building spatial distribution and population after the disaster.\n// Use the ESA WorldCover 10m v200 dataset\nvar dataset = ee.ImageCollection('ESA/WorldCover/v200')\n  .first() // Take the first Image\n  .select('Map') // Select the 'Map' band\n  .clip(aoi);\n\n// Get the projection information of ESA WorldCover\nvar worldCoverProjection = dataset.projection();\n\n// Reproject the flood layer to the scale of ESA WorldCover\nvar flooded_res = flooded.reproject({\n  crs: worldCoverProjection\n});\n\n// Add the ESA WorldCover layer to the map\nvar worldCoverVis = {\n  min: 10,\n  max: 100,\n  palette: [\n    '#006400', '#ffbb22', '#ffff4c', '#f096ff', '#fa0000',\n    '#b4b4b4', '#f0f0f0', '#0064c8', '#0096a0', '#00cf75',\n    '#fae6a0'\n  ]\n};\nMap.addLayer(dataset, worldCoverVis, 'ESA WorldCover');\n\n// Select cropland category (class code 40 corresponds to cropland)\nvar cropland = dataset.eq(40);\n// Calculate affected cropland area\nvar croplandAffected = flooded_res.updateMask(cropland);\n\n// Select built-up category (class code 50)\nvar buildland = dataset.eq(50);\nvar class_prediction = prediction.updateMask(prediction.eq(0));\n\n// ---------- Construct Building Spatial Distribution -----------\n// Mask classification results using built-up area masks after resampling\nvar maskedClassPrediction = prediction.updateMask(builtUp);\n\n// Convert masked classification results to 1-bit depth black and white images\nvar maskedClassPredictionBinary = maskedClassPrediction.multiply(255).toByte();\n\n// Add converted classification results to the map\nMap.addLayer(maskedClassPredictionBinary, {min: 0, max: 1}, 'Built-up Area Prediction (Binary)');\n\n// ---------- Load population data -----------\n// Load population data from GHSL\nvar population = ee.Image('JRC/GHSL/P2023A/GHS_POP/2020')\n  .clip(aoi);\n// Get GHSL projection\nvar GHSLprojection = population.projection();\n// Reproject flood layer to GHSL scale\nvar flooded_res1 = flooded.reproject({\n  crs: GHSLprojection\n});\n\n// Calculate flood-affected population by applying the flood and population masks\nvar floodedPopulation = population\n  .updateMask(flooded_res1)\n  .updateMask(population);\nConstruct the function about calculating the area of affected croplands, built-up areas and population.\nfunction calculateFloodImpactStats(Affected_Cropland, Affected_Builtup, Flooded_Population, Flooded_Areas,  polarization, aoi) {\n  // Calculate the area of each affected cropland pixel\n  var affectedCroplandArea = Affected_Cropland.multiply(ee.Image.pixelArea());\n\n  // Calculate the sum of the affected cropland area\n  var croplandStats = affectedCroplandArea.reduceRegion({\n    reducer: ee.Reducer.sum(),\n    geometry: aoi,\n    scale: 10, // Use the original resolution of the WorldCover dataset (10m)\n    maxPixels: 1e9\n  });\n\n  // Convert the affected cropland area from square meters to hectares\n  var croplandAreaHectares = ee.Number(croplandStats.get('b1')).divide(10000).round();\n\n  // Calculate the area of each affected built-up land pixel\n  var affectedBuildlandArea = Affected_Builtup.multiply(ee.Image.pixelArea());\n\n  // Calculate the sum of the affected built-up land area\n  var buildlandStats = affectedBuildlandArea.reduceRegion({\n    reducer: ee.Reducer.sum(),\n    geometry: aoi,\n    scale: 10, // Use the original resolution of the WorldCover dataset (10m)\n    maxPixels: 1e9\n  });\n\n  // Convert the affected built-up land area from square meters to hectares\n  var buildlandAreaHectares = ee.Number(buildlandStats.get('b1')).divide(10000).round();\n\n  // Calculate the number of affected population\n  var populationStats = Flooded_Population.reduceRegion({\n    reducer: ee.Reducer.sum(),\n    geometry: aoi,\n    scale: 100,\n    maxPixels: 1e9\n  });\n\n  // Get the affected population count\n  var affectedPopulation = ee.Number(populationStats.get('b1')).round();\n\n  // Calculate the area of the flooded regions\n  var flood_pixelarea = Flooded_Areas.multiply(ee.Image.pixelArea());\n\n  // Calculate the sum of the flooded area\n  var flood_stats = flood_pixelarea.reduceRegion({\n    reducer: ee.Reducer.sum(),\n    geometry: aoi,\n    scale: 10,\n    bestEffort: true\n  });\n\n  // Convert the flooded area from square meters to hectares\n  var flood_area_ha = ee.Number(flood_stats.get('b1')).divide(10000).round();\n\n  // Calculate the total area of the selected region\n  var totalArea = ee.Image.pixelArea().reduceRegion({\n    reducer: ee.Reducer.sum(),\n    geometry: aoi,\n    scale: 10,\n    maxPixels: 1e13\n  });\n\n  // Convert the total area from square meters to hectares\n  var totalAreaHectares = ee.Number(totalArea.get('area')).divide(10000).round();\n\n  // Return an object containing all the calculated results\n  return {\n    croplandAreaHectares: croplandAreaHectares,\n    buildlandAreaHectares: buildlandAreaHectares,\n    affectedPopulation: affectedPopulation,\n    floodAreaHectares: flood_area_ha,\n    totalAreaHectares: totalAreaHectares\n  };\n}\nAffected Build-up Areas \nAffected Cropland Areas \nAffected Building Distribution of One City \n\n\n\n\nCreate a map instance and Set the center point and zoom level of the map. Focus on the country that needs to be analysed.\n\nMap.setCenter(21.0842, 31.9395, 10);\n\nvar admin = ee.FeatureCollection(\"projects/ee-hanmengyuan9/assets/libya\");\nvar geometry=admin.filter(ee.Filter.eq('shapeName','Al Marj'));\n\n// Add the filtered feature collection to the map\nMap.addLayer(geometry,{color:'grey'},'Al Marj');\n\n// Add Google Satellite imagery to the map\nMap.setOptions('SATELLITE');\n\n// Set the map center to the area of interest\nMap.centerObject(geometry, 8);\n\nUser interface layout\n\nThe UI design is structured to facilitate the interpretation and analysis of data regarding flooded regions. The layout can be divided into distinct zones: the map visualization area, area selection and the statistical information panel.\nThe map visualization provides a geographical representation of the affected areas, employing a color-coded legend for immediate visual differentiation between various categories such as ‘Affected Cropland’, ‘Affected Built-up’, ‘Flooded Areas’, and ‘Affected Building Footprints’. The choice of contrasting colors enhances the readability of the data on a spatial scale.\n// Load the products we generated\nvar Affected_Builtup = ee.Image('projects/ee-zhengying11140/assets/Affected_Builtup');\nvar Flooded_Population = ee.Image('projects/ee-zhengying11140/assets/Flooded_Population');\nvar Flooded_Areas = ee.Image('projects/ee-zhengying11140/assets/Flooded_Areas');\nvar Classification_Result = ee.Image('projects/ee-zhengying11140/assets/Classification_Result');\nvar Affected_Cropland = ee.Image('projects/ee-zhengying11140/assets/Affected_Cropland');\nvar BuildingFootprints = ee.Image('projects/ee-zhengying11140/assets/MaskedClassPrediction');\n\n// Set raster pixels with no value to transparent\nvar Flooded_Areas_Unmasked = Flooded_Areas.unmask(0).selfMask();\nvar Affected_Cropland_Unmasked = Affected_Cropland.unmask(0).selfMask();\nvar Affected_Builtup_Unmasked = Affected_Builtup.unmask(0).selfMask();\nvar BuildingFootprints_Unmasked = BuildingFootprints.unmask(0).selfMask();\n\n// Define visualisation parameters for flooded areas and affected cropland\n// affected built-up land and affected building footprints\nvar floodedAreasVis = {\n  palette: ['blue'],\n  opacity: 0.7\n};\n\nvar affectedCroplandVis = {\n  palette: ['yellow'],\n  opacity: 0.7\n};\n\nvar affectedBuiltuplandVis = {\n  palette: ['red'],\n  opacity: 0.7\n};\n\nvar affectedBuildingFootprintsVis = {\n  palette: ['#050509'],\n  opacity: 0.7\n};\n\n// Add layers accordingly\nMap.addLayer(Flooded_Areas_Unmasked, floodedAreasVis, 'Flooded Areas');\nMap.addLayer(Affected_Cropland_Unmasked, affectedCroplandVis, 'Affected Cropland');\nMap.addLayer(Affected_Builtup_Unmasked, affectedBuiltuplandVis, 'Affected Built-up');\nMap.addLayer(BuildingFootprints_Unmasked, affectedBuildingFootprintsVis, 'Affected Building Footprints');\nOn the top-left of the UI is a tool bar which enables the user to freely select the area they wish to analyse.\n// Create a drawing tool\nvar drawingTools = Map.drawingTools();\ndrawingTools.setShown(true);\nOn the right side of the map is the statistical information panel, which presents crucial data in a concise, tabulated format. This includes metrics such as affected cropland area (in hectares), affected built-up area, affected population, total flood area, and the total area under consideration. The numerical data is clearly delineated which directly answer the questions examined in this project. If the user want to choose another area, he can click the “clear” button on the bottom of the panel and repeat the process of selecting.\n// Create a panel to display the statistics and clear button\nvar panel = ui.Panel({\n  style: {\n    position: 'bottom-right',\n    width: '250px',\n    padding: '8px',\n    backgroundColor: 'white',\n    fontFamily: 'Arial',\n    fontSize: '14px'\n  }\n});\n\n// Create a title label\nvar titleLabel = ui.Label({\n  value: 'Flood Impact Statistics',\n  style: {fontWeight: 'bold', fontSize: '18px', margin: '10px 0'}\n});\n\n// Create labels to display the statistics\nvar croplandLabel = ui.Label({style: {color: '#CD8B0E', fontSize: '16px'}});\nvar buildlandLabel = ui.Label({style: {color: 'red', fontSize: '16px'}});\nvar populationLabel = ui.Label({style: {color: 'green', fontSize: '16px'}});\nvar floodAreaLabel = ui.Label({style: {color: '#415FC1', fontSize: '16px'}});\nvar totalAreaLabel = ui.Label({style: {color: '#243F81', fontSize: '16px'}});\n\n// Create a clear button\nvar clearButton = ui.Button({\n  label: 'Clear',\n  style: {backgroundColor: '#FF5722', color: 'black', fontSize: '14px', margin: '10px 0'},\n  onClick: function() {\n    drawingTools.layers().reset();\n    croplandLabel.setValue('');\n    buildlandLabel.setValue('');\n    populationLabel.setValue('');\n    floodAreaLabel.setValue('');\n    totalAreaLabel.setValue('');\n  }\n});\n\n// Add the labels and clear button to the panel\npanel.add(titleLabel);\npanel.add(ui.Label('Affected Cropland (ha):'));\npanel.add(croplandLabel);\npanel.add(ui.Label('Affected Built-up (ha):'));\npanel.add(buildlandLabel);\npanel.add(ui.Label('Affected Population:'));\npanel.add(populationLabel);\npanel.add(ui.Label('Flood Area (ha):'));\npanel.add(floodAreaLabel);\npanel.add(ui.Label('Total Area (ha):'));\npanel.add(totalAreaLabel);\npanel.add(clearButton);\nOn the left-bottom is a panel of lengend, which represents different color of the land use.\n// Create a legend panel\nvar legend = ui.Panel({\n  style: {\n    position: 'bottom-left',\n    padding: '8px'\n  }\n});\n\n// Create a legend title\nvar legendTitle = ui.Label({\n  value: 'Legend',\n  style: {fontWeight: 'bold', fontSize: '18px', margin: '0 0 4px 0'}\n});\n\nlegend.add(legendTitle);\n\n// Create a legend row\nvar makeRow = function(color, name) {\n  var colorBox = ui.Label({\n    style: {\n      backgroundColor: color,\n      padding: '8px',\n      margin: '0 0 4px 0'\n    }\n  });\n  var description = ui.Label({\n    value: name,\n    style: {margin: '0 0 4px 6px'}\n  });\n  return ui.Panel({\n    widgets: [colorBox, description],\n    layout: ui.Panel.Layout.Flow('horizontal')\n  });\n};\n\n// Add legend items\nlegend.add(makeRow('yellow', 'Affected Cropland'));\nlegend.add(makeRow('red', 'Affected Built-up'));\nlegend.add(makeRow('#415FC1', 'Flooded Areas'));\nlegend.add(makeRow('#050509', 'Affected Building Footprints'));\n\n// Add the legend to the map\nMap.add(legend);\n\nData transmission\n\nThe code loads a series of pre-generated raster images representing different aspects of the flood impact such as ‘Affected Builtup’, ‘Flooded Population’, etc. These rasters are processed to set non-valued pixels to transparent, which would allow for overlaying them on the map without obscuring other layers.\n// Load the products we generated\nvar Affected_Builtup = ee.Image('projects/ee-zhengying11140/assets/Affected_Builtup');\nvar Flooded_Population = ee.Image('projects/ee-zhengying11140/assets/Flooded_Population');\nvar Flooded_Areas = ee.Image('projects/ee-zhengying11140/assets/Flooded_Areas');\nvar Classification_Result = ee.Image('projects/ee-zhengying11140/assets/Classification_Result');\nvar Affected_Cropland = ee.Image('projects/ee-zhengying11140/assets/Affected_Cropland');\nvar BuildingFootprints = ee.Image('projects/ee-zhengying11140/assets/MaskedClassPrediction');\nWhen the user selects an area on the map, the onDraw event triggers data capture. Then, a variable aoi is returned, which represents geometry, and this variable is brought into the function calculateFloodImpactStats for calculation. The equations are encapsulated to calculate the full range of values required. When the user needs to calculate new data, just refresh the value of aoi, which is very efficient.\n// Listen for the draw end event\ndrawingTools.onDraw(function(geometry) {\n  // Get the drawn geometry\n  var aoi = geometry;\n  \n  // Display a calculating message\n  croplandLabel.setValue('Calculating...');\n  buildlandLabel.setValue('Calculating...');\n  populationLabel.setValue('Calculating...');\n  floodAreaLabel.setValue('Calculating...');\n  totalAreaLabel.setValue('Calculating...');\n  \n  // Call the calculation function and update the labels\n  var stats = calculateFloodImpactStats(Affected_Cropland, Affected_Builtup, Flooded_Population, Flooded_Areas, BuildingFootprints, 'VV', aoi);\nA function calculateFloodImpactStats is defined to compute statistics such as the area of affected cropland and built-up land in hectares, the number of affected population, and the area of flooded regions, based on the pixel values of the respective images within the selected AOI. The calculations use GEE’s reduction methods over the specified region at a defined scale.\nfunction calculateFloodImpactStats(Affected_Cropland, Affected_Builtup, Flooded_Population, Flooded_Areas, BuildingFootprints, polarization, aoi) {\n  // Calculate the area of each affected cropland pixel\n  var affectedCroplandArea = Affected_Cropland.multiply(ee.Image.pixelArea());\n\n  // Calculate the sum of the affected cropland area\n  var croplandStats = affectedCroplandArea.reduceRegion({\n    reducer: ee.Reducer.sum(),\n    geometry: aoi,\n    scale: 10, \n    maxPixels: 1e9\n  });\n\n  var croplandAreaHectares = ee.Number(croplandStats.get('b1')).divide(10000).round();\n\n  // Calculate the area of each affected built-up land pixel\n  var affectedBuildlandArea = Affected_Builtup.multiply(ee.Image.pixelArea());\n\n  // Calculate the sum of the affected built-up land area\n  var buildlandStats = affectedBuildlandArea.reduceRegion({\n    reducer: ee.Reducer.sum(),\n    geometry: aoi,\n    scale: 10,\n    maxPixels: 1e9\n  });\n\n  var buildlandAreaHectares = ee.Number(buildlandStats.get('b1')).divide(10000).round();\n\n  // Calculate the number of affected population\n  var populationStats = Flooded_Population.reduceRegion({\n    reducer: ee.Reducer.sum(),\n    geometry: aoi,\n    scale: 100,\n    maxPixels: 1e9\n  });\n\n  var affectedPopulation = ee.Number(populationStats.get('b1')).round();\n\n  // Calculate the area of flooded regions\n  var flood_pixelarea = Flooded_Areas.multiply(ee.Image.pixelArea());\n\n  var flood_stats = flood_pixelarea.reduceRegion({\n    reducer: ee.Reducer.sum(),\n    geometry: aoi,\n    scale: 10,\n    bestEffort: true\n  });\n\n  var flood_area_ha = ee.Number(flood_stats.get('b1')).divide(10000).round();\n\n\n  // Calculate the total area of the selected AOI\n  var totalArea = ee.Image.pixelArea().reduceRegion({\n    reducer: ee.Reducer.sum(),\n    geometry: aoi,\n    scale: 10,\n    maxPixels: 1e13\n  });\n\n  var totalAreaHectares = ee.Number(totalArea.get('area')).divide(10000).round();\n\n // Return an object containing all the calculated results\n  return {\n    croplandAreaHectares: croplandAreaHectares,\n    buildlandAreaHectares: buildlandAreaHectares,\n    affectedPopulation: affectedPopulation,\n    floodAreaHectares: flood_area_ha,\n    totalAreaHectares: totalAreaHectares\n  };\n}\n\n\n\n\nGithub For the Application\nApplication\nApplication code\nUI code"
  },
  {
    "objectID": "index.html#project-summary",
    "href": "index.html#project-summary",
    "title": "Al Marj Flood Impact Comprehensive Evaluation System",
    "section": "",
    "text": "This project crafts an application within Google Earth Engine to evaluate the repercussions of the substantial flood event that transpired in Al Marj, Libya, during September 2023. The application integrates satellite imagery for flood mapping, land cover data for analyzing affected land cover types, and random forest classification to detect affected buildings. Additionally, it utilizes population grid data to estimate the number of people affected by the flood. The results provide a comprehensive assessment of the flood extent, affected land cover areas, impacted buildings, and the affected population, which is crucial for informing disaster response and management efforts.\n\n\n\nStudy Area\n\n\n\n\nIn September 2023, severe flooding in Al Marj, Libya, caused significant damage to infrastructure and displaced numerous people. Rapid and accurate assessment of the flood’s impact is essential for effective disaster response and management. This application aims to address the following key research questions:\n\nWhat is the total area affected by the flooding?\nWhat is the extent of damage affected by the flooding to different land cover types, particularly agricultural land and built-up areas? How the the flooding affact the area of Buildings?\nHow many people are estimated to be affected by the flooding?\n\n\n\n\nGovernment departments and international organizations:\nBy visualizing flooded areas, affected buildings, and population data, our project enables these departments to quickly and accurately assess the disaster situation. This facilitates effective rescue and reconstruction planning, as well as optimization of future urban development, land use, and drainage systems.\nAffected communities and the public:\nThe spatial distribution map of the flooded area generated by the project can help the affected communities and the public intuitively understand the scope and severity of the flood impact, and take timely countermeasures.\n\n\n\nSentinel-1 Satellite Image: Sentinel-1 collects C-band synthetic aperture radar (SAR) imagery at a variety of polarizations and resolutions. We use it to detect flood coverage.\nSentinel-2 Satellite Image: Sentinel-2 is a wide-swath, high-resolution, multispectral imaging mission with a global 5-day revisit frequency.\nSurface Water:JRC Global Surface Water Metadata contains maps of the location and temporal distribution of surface water. Year-round water is filtered using the JRC Global Water Seasonal Data layer.\nDEM:WWF HydroSHEDS Void-Filled DEM excludes areas with gradients greater than 5%.\nLand Classification: ESA WorldCover 10m v200 ESA WorldCover10m contains 11 land cover classes based on Sentinel-1 and Sentinel-2 data.\nPopulation: GHSL: Global population surfaces 1975-2030 contains the spatial distribution of residential population, expressed as the absolute number of inhabitants of the cell.\n\n\n\nFlood extent mapping:\nThe areas affected by the flood are identified by calculating the difference between pre-flood and post-flood images.\nLand cover impact assessment: By overlaying the flood extent layer with the land cover, the affected built-up areas and croplands are assessed.\nBuilding damage assessment:\nThe random forest classification algorithm is applied to the Sentinel-2 multispectral imagery to extract buildings within the built-up areas. The accuracy is evaluated using a confusion matrix.\nPopulation impact assessment:\nBy overlaying the flood extent map with the population grid, the application calculates the total number of individuals residing within the inundated areas.\n\n\n\nProcedure\n\n\n\n\n\nUsers will be able to interact with the perform:\n\nDraw an Area of Interest (AOI): Users can draw a polygon on the map to define a specific area they want to analyze.\nObtain information: The application will process the data within the AOI and display the key indicators in the results panel, including Total Area, Flood Extent Areas, Damaged Built-Up Areas, Damaged Cropland Areas, Estimated Affected Population.\nVisualization: The map will display visual overlays within the AOI that include Affected Built-Up, Affected Cropland, A ffected Building Footprints, and Flood Areas. This setup clearly identifies flood-impacted regions.\n\n\n\n\nInterface"
  },
  {
    "objectID": "index.html#the-application",
    "href": "index.html#the-application",
    "title": "Al Marj Flood Impact Comprehensive Evaluation System",
    "section": "",
    "text": "This is our Earth Engine application."
  },
  {
    "objectID": "index.html#how-it-works",
    "href": "index.html#how-it-works",
    "title": "Al Marj Flood Impact Comprehensive Evaluation System",
    "section": "",
    "text": "1. Flood Area Analysis\n1.1 Data Preprocessing\nWe imported the administrative boundary data of Al Marj region and filtered the area of interest (AOI).\n// Import the administrative boundary of Libya and filter the target region (Al Marj) as the area of interest (AOI)\nvar admin = ee.FeatureCollection(\"projects/ee-hanmengyuan9/assets/libya\");\nvar geometry = admin.filter(ee.Filter.eq('shapeName', 'Al Marj'));\nMap.addLayer(geometry, {color: 'grey'}, 'Al Marj');\nAnd we selected the Sentinel-1 SAR image collection, set parameters and filter images for the flood periods.\n// Define the time periods before and after the flood event\nvar before_start = '2023-09-01';\nvar before_end = '2023-09-15';\nvar after_start = '2023-09-23';\nvar after_end = '2023-09-30';\n\n// Set sensor parameters for the satellite data collection\nvar polarization = (\"VH\", \"VV\");\nvar pass_direction = \"DESCENDING\";\nvar difference_threshold = 1.00; \n\n// Defining the area of interest based on the filtered geometry\nvar aoi = geometry;\n\n// Filtering the satellite image collection based on the specified parameters\nvar collection = ee.ImageCollection('COPERNICUS/S1_GRD')\n  .filter(ee.Filter.eq('instrumentMode', 'IW'))\n  .filter(ee.Filter.listContains('transmitterReceiverPolarisation', polarization))\n  .filter(ee.Filter.eq('orbitProperties_pass', pass_direction))\n  .filter(ee.Filter.eq('resolution_meters', 10))\n  .filterBounds(aoi)\n  .select(polarization);\n  \n// Filter the image collection to obtain images from before and after the flood\nvar before_collection = collection.filterDate(before_start, before_end);\nvar after_collection = collection.filterDate(after_start, after_end);\nThen, we mosaicked, clipped, and applied speckle noise reduction to the filtered before and after image collections to optimize data quality.\n// Create a mosaic of selected tiles and clip to study area\nvar before = before_collection.mosaic().clip(aoi);\nvar after = after_collection.mosaic().clip(aoi);\n\n// Apply reduce the radar speckle by smoothing  \nvar smoothing_radius = 50;\nvar before_filtered = before.focal_mean(smoothing_radius, 'circle', 'meters');\nvar after_filtered = after.focal_mean(smoothing_radius, 'circle', 'meters');\n1.2 Flood Extent Extraction\nWe extracted the flood extent using threshold segmentation and further optimize the flood extent using surface water data, connectivity analysis, and terrain filtering.\n// Calculate the difference between the before and after images\nvar difference = after_filtered.divide(before_filtered);\n\n// Apply the predefined difference-threshold and create the flood extent mask \nvar threshold = difference_threshold;\nvar difference_binary = difference.gt(threshold);\n\n// Refine flood result using additional datasets\n      \n      // Include JRC layer on surface water seasonality to mask flood pixels from areas\n      // of \"permanent\" water (where there is water &gt; 10 months of the year)\n      var swater = ee.Image('JRC/GSW1_0/GlobalSurfaceWater').select('seasonality');\n      var swater_mask = swater.gte(10).updateMask(swater.gte(10));\n      \n      // Flooded layer where perennial water bodies (water &gt; 10 mo/yr) is assigned a 0 value\n      var flooded_mask = difference_binary.where(swater_mask,0);\n      // final flooded area without pixels in perennial waterbodies\n      var flooded = flooded_mask.updateMask(flooded_mask);\n      \n      // Compute connectivity of pixels to eliminate those connected to 8 or fewer neighbours\n      // This operation reduces noise of the flood extent product \n      var connections = flooded.connectedPixelCount();    \n      var flooded = flooded.updateMask(connections.gte(8));\n      \n      // Mask out areas with more than 5 percent slope using a Digital Elevation Model \n      var DEM = ee.Image('WWF/HydroSHEDS/03VFDEM');\n      var terrain = ee.Algorithms.Terrain(DEM);\n      var slope = terrain.select('slope');\n      var flooded = flooded.updateMask(slope.lt(5));\n1.3 Flood Area Calculation\nWe calculated the flood inundation area based on pixel area and regional statistics.\n// Calculate flood extent area\n// Create a raster layer containing the area information of each pixel \nvar flood_pixelarea = flooded.select(polarization)\n  .multiply(ee.Image.pixelArea());\n\n// Sum the areas of flooded pixels\n// default is set to 'bestEffort: true' in order to reduce computation time, for a more \n// accurate result set bestEffort to false and increase 'maxPixels'. \nvar flood_stats = flood_pixelarea.reduceRegion({\n  reducer: ee.Reducer.sum(),              \n  geometry: aoi,\n  scale: 10, // native resolution \n  //maxPixels: 1e9,\n  bestEffort: true\n  });\n\n// Convert the flood extent to hectares (area calculations are originally given in meters)  \nvar flood_area_ha = flood_stats\n  .getNumber(polarization)\n  .divide(10000)\n  .round();\n\n\n\nFlooded Area\n\n\n2. Identify buildings affected by flooding\n2.1 Data preprocessing\nThe obtained Sentinel-2 image is filtered, processed, cropped, and a preliminary image is generated. A mask is then applied to the data based on NDWI and NDVI thresholds (0.3 and 0.2, respectively) to filter out non-water and low vegetation cover areas.\n// Define an array of band names for Sentinel-2 imagery\nvar bands = ['B2', 'B3', 'B4', 'B5', 'B6', 'B7', 'B8', 'B8A', 'B11', 'B12'];\n\n// Create an ImageCollection of Sentinel-2 surface reflectance images\nvar sentinel2 = ee.ImageCollection('COPERNICUS/S2_SR')\n  .filter(ee.Filter.date(before_start, after_end)) // Filter images by date range\n  .filter(ee.Filter.lt('CLOUDY_PIXEL_PERCENTAGE', 10)) // Filter images with less than 10% cloud cover\n  .mean() // Compute the mean value of each pixel across the filtered images\n  .select(bands) // Select the specified bands\n  .clip(geometry); // Clip the resulting image to the specified geometry\n\n// Define visualization parameters for RGB composite\nvar s_rgb = {\n  min: 0.0, // Minimum value for stretching the image\n  max: 3000, // Maximum value for stretching the image\n  bands: ['B4', 'B3', 'B2'], // Red, Green, Blue bands for the composite\n  opacity: 1 // Opacity of the layer\n};\n\n// Calculate NDVI (Normalized Difference Vegetation Index)\nvar ndvi = sentinel2.normalizedDifference(['B8', 'B4']).select(['nd'], ['ndvi']);\n\n// Calculate NDWI (Normalized Difference Water Index)\nvar ndwi = sentinel2.normalizedDifference(['B3', 'B8']).select(['nd'], ['ndwi']);\n\n// Create a masked image based on NDWI and NDVI thresholds and add NDVI band\nvar image = sentinel2\n  .updateMask(ndwi.lt(0.3)) // Mask pixels with NDWI less than 0.3\n  .updateMask(ndvi.lt(0.2)) // Mask pixels with NDVI less than 0.2\n  .addBands(ndvi); // Add the NDVI band to the image\n2.2 RF analysis\nTo improve the accuracy of the training building model, we will classify and identify different features (such as buildings, farmland, deserts, etc.) together by Random Forest.\nvar building_points = ee.FeatureCollection.randomPoints(buildings2, 3000).map(function(i) {\n  return i.set({'class': 0});\n});\nvar farm_points = ee.FeatureCollection.randomPoints(farmland, 3000).map(function(i) {\n  return i.set({'class': 1});\n});\nvar desert_points = ee.FeatureCollection.randomPoints(desert, 3000).map(function(i) {\n  return i.set({'class': 2});\n});\nvar water_points = ee.FeatureCollection.randomPoints(water, 3000).map(function(i) {\n  return i.set({'class': 3});\n});\nvar road_points = ee.FeatureCollection.randomPoints(road, 3000).map(function(i) {\n  return i.set({'class': 4});\n});\nvar parking_points = ee.FeatureCollection.randomPoints(parking, 3000).map(function(i) {\n  return i.set({'class': 5});\n});\nCombine the random points and split them into training and validation sets and we used the split ratio equal to 0.7.\n// Combine the random points for each land cover class into a single FeatureCollection\nvar sample = ee.FeatureCollection([\n  building_points,\n  farm_points,\n  desert_points,\n  water_points,\n  road_points,\n  parking_points\n])\n.flatten()  // Flatten the FeatureCollection\n.randomColumn(); // Add a random column to the FeatureCollection for splitting\n\n// Define the split ratio for training and validation samples\nvar split = 0.7;\n\n// Create training sample by filtering the sample FeatureCollection where the random column is less than the split ratio\nvar training_sample = sample.filter(ee.Filter.lt('random', split));\n\n// Create validation sample by filtering the sample FeatureCollection where the random column is greater than or equal to the split ratio\nvar validation_sample = sample.filter(ee.Filter.gte('random', split));\nSample the image using the training and validation points and Train a Random Forest classifier using the training samples.\n// Sample the image using the training sample\nvar training = image.sampleRegions({\n  collection: training_sample,\n  properties: ['class'],\n  scale: 10,\n});\n\n// Sample the image using the validation sample\nvar validation = image.sampleRegions({\n  collection: validation_sample,\n  properties: ['class'],\n  scale: 10\n});\n\n// Train a Random Forest classifier using the training samples\nvar model = ee.Classifier.smileRandomForest(400)\n  .train(training, 'class');\nClassify the image using the trained model and extract the building class from the prediction.\n// Classify the image using the trained model\nvar prediction = image.classify(model);\n\n// Extract the building class from the prediction by masking pixels that are not classified as buildings (class 0)\nvar building_prediction = prediction.updateMask(prediction.eq(0));\n3.Calculate the built-up areas, croplands, buildings footprint and population after the disaster\nImport ESA WorldCover into the map and extract cropland and built-up land from it. By intersecting the Build-up land with the identified buildings, we will focus on the disaster situation of the buildings in the built-up area. Finally, the flood data mask was used to obtain the cropland, built-up areas, building spatial distribution and population after the disaster.\n// Use the ESA WorldCover 10m v200 dataset\nvar dataset = ee.ImageCollection('ESA/WorldCover/v200')\n  .first() // Take the first Image\n  .select('Map') // Select the 'Map' band\n  .clip(aoi);\n\n// Get the projection information of ESA WorldCover\nvar worldCoverProjection = dataset.projection();\n\n// Reproject the flood layer to the scale of ESA WorldCover\nvar flooded_res = flooded.reproject({\n  crs: worldCoverProjection\n});\n\n// Add the ESA WorldCover layer to the map\nvar worldCoverVis = {\n  min: 10,\n  max: 100,\n  palette: [\n    '#006400', '#ffbb22', '#ffff4c', '#f096ff', '#fa0000',\n    '#b4b4b4', '#f0f0f0', '#0064c8', '#0096a0', '#00cf75',\n    '#fae6a0'\n  ]\n};\nMap.addLayer(dataset, worldCoverVis, 'ESA WorldCover');\n\n// Select cropland category (class code 40 corresponds to cropland)\nvar cropland = dataset.eq(40);\n// Calculate affected cropland area\nvar croplandAffected = flooded_res.updateMask(cropland);\n\n// Select built-up category (class code 50)\nvar buildland = dataset.eq(50);\nvar class_prediction = prediction.updateMask(prediction.eq(0));\n\n// ---------- Construct Building Spatial Distribution -----------\n// Mask classification results using built-up area masks after resampling\nvar maskedClassPrediction = prediction.updateMask(builtUp);\n\n// Convert masked classification results to 1-bit depth black and white images\nvar maskedClassPredictionBinary = maskedClassPrediction.multiply(255).toByte();\n\n// Add converted classification results to the map\nMap.addLayer(maskedClassPredictionBinary, {min: 0, max: 1}, 'Built-up Area Prediction (Binary)');\n\n// ---------- Load population data -----------\n// Load population data from GHSL\nvar population = ee.Image('JRC/GHSL/P2023A/GHS_POP/2020')\n  .clip(aoi);\n// Get GHSL projection\nvar GHSLprojection = population.projection();\n// Reproject flood layer to GHSL scale\nvar flooded_res1 = flooded.reproject({\n  crs: GHSLprojection\n});\n\n// Calculate flood-affected population by applying the flood and population masks\nvar floodedPopulation = population\n  .updateMask(flooded_res1)\n  .updateMask(population);\nConstruct the function about calculating the area of affected croplands, built-up areas and population.\nfunction calculateFloodImpactStats(Affected_Cropland, Affected_Builtup, Flooded_Population, Flooded_Areas,  polarization, aoi) {\n  // Calculate the area of each affected cropland pixel\n  var affectedCroplandArea = Affected_Cropland.multiply(ee.Image.pixelArea());\n\n  // Calculate the sum of the affected cropland area\n  var croplandStats = affectedCroplandArea.reduceRegion({\n    reducer: ee.Reducer.sum(),\n    geometry: aoi,\n    scale: 10, // Use the original resolution of the WorldCover dataset (10m)\n    maxPixels: 1e9\n  });\n\n  // Convert the affected cropland area from square meters to hectares\n  var croplandAreaHectares = ee.Number(croplandStats.get('b1')).divide(10000).round();\n\n  // Calculate the area of each affected built-up land pixel\n  var affectedBuildlandArea = Affected_Builtup.multiply(ee.Image.pixelArea());\n\n  // Calculate the sum of the affected built-up land area\n  var buildlandStats = affectedBuildlandArea.reduceRegion({\n    reducer: ee.Reducer.sum(),\n    geometry: aoi,\n    scale: 10, // Use the original resolution of the WorldCover dataset (10m)\n    maxPixels: 1e9\n  });\n\n  // Convert the affected built-up land area from square meters to hectares\n  var buildlandAreaHectares = ee.Number(buildlandStats.get('b1')).divide(10000).round();\n\n  // Calculate the number of affected population\n  var populationStats = Flooded_Population.reduceRegion({\n    reducer: ee.Reducer.sum(),\n    geometry: aoi,\n    scale: 100,\n    maxPixels: 1e9\n  });\n\n  // Get the affected population count\n  var affectedPopulation = ee.Number(populationStats.get('b1')).round();\n\n  // Calculate the area of the flooded regions\n  var flood_pixelarea = Flooded_Areas.multiply(ee.Image.pixelArea());\n\n  // Calculate the sum of the flooded area\n  var flood_stats = flood_pixelarea.reduceRegion({\n    reducer: ee.Reducer.sum(),\n    geometry: aoi,\n    scale: 10,\n    bestEffort: true\n  });\n\n  // Convert the flooded area from square meters to hectares\n  var flood_area_ha = ee.Number(flood_stats.get('b1')).divide(10000).round();\n\n  // Calculate the total area of the selected region\n  var totalArea = ee.Image.pixelArea().reduceRegion({\n    reducer: ee.Reducer.sum(),\n    geometry: aoi,\n    scale: 10,\n    maxPixels: 1e13\n  });\n\n  // Convert the total area from square meters to hectares\n  var totalAreaHectares = ee.Number(totalArea.get('area')).divide(10000).round();\n\n  // Return an object containing all the calculated results\n  return {\n    croplandAreaHectares: croplandAreaHectares,\n    buildlandAreaHectares: buildlandAreaHectares,\n    affectedPopulation: affectedPopulation,\n    floodAreaHectares: flood_area_ha,\n    totalAreaHectares: totalAreaHectares\n  };\n}\nAffected Build-up Areas \nAffected Cropland Areas \nAffected Building Distribution of One City \n\n\n\n\nCreate a map instance and Set the center point and zoom level of the map. Focus on the country that needs to be analysed.\n\nMap.setCenter(21.0842, 31.9395, 10);\n\nvar admin = ee.FeatureCollection(\"projects/ee-hanmengyuan9/assets/libya\");\nvar geometry=admin.filter(ee.Filter.eq('shapeName','Al Marj'));\n\n// Add the filtered feature collection to the map\nMap.addLayer(geometry,{color:'grey'},'Al Marj');\n\n// Add Google Satellite imagery to the map\nMap.setOptions('SATELLITE');\n\n// Set the map center to the area of interest\nMap.centerObject(geometry, 8);\n\nUser interface layout\n\nThe UI design is structured to facilitate the interpretation and analysis of data regarding flooded regions. The layout can be divided into distinct zones: the map visualization area, area selection and the statistical information panel.\nThe map visualization provides a geographical representation of the affected areas, employing a color-coded legend for immediate visual differentiation between various categories such as ‘Affected Cropland’, ‘Affected Built-up’, ‘Flooded Areas’, and ‘Affected Building Footprints’. The choice of contrasting colors enhances the readability of the data on a spatial scale.\n// Load the products we generated\nvar Affected_Builtup = ee.Image('projects/ee-zhengying11140/assets/Affected_Builtup');\nvar Flooded_Population = ee.Image('projects/ee-zhengying11140/assets/Flooded_Population');\nvar Flooded_Areas = ee.Image('projects/ee-zhengying11140/assets/Flooded_Areas');\nvar Classification_Result = ee.Image('projects/ee-zhengying11140/assets/Classification_Result');\nvar Affected_Cropland = ee.Image('projects/ee-zhengying11140/assets/Affected_Cropland');\nvar BuildingFootprints = ee.Image('projects/ee-zhengying11140/assets/MaskedClassPrediction');\n\n// Set raster pixels with no value to transparent\nvar Flooded_Areas_Unmasked = Flooded_Areas.unmask(0).selfMask();\nvar Affected_Cropland_Unmasked = Affected_Cropland.unmask(0).selfMask();\nvar Affected_Builtup_Unmasked = Affected_Builtup.unmask(0).selfMask();\nvar BuildingFootprints_Unmasked = BuildingFootprints.unmask(0).selfMask();\n\n// Define visualisation parameters for flooded areas and affected cropland\n// affected built-up land and affected building footprints\nvar floodedAreasVis = {\n  palette: ['blue'],\n  opacity: 0.7\n};\n\nvar affectedCroplandVis = {\n  palette: ['yellow'],\n  opacity: 0.7\n};\n\nvar affectedBuiltuplandVis = {\n  palette: ['red'],\n  opacity: 0.7\n};\n\nvar affectedBuildingFootprintsVis = {\n  palette: ['#050509'],\n  opacity: 0.7\n};\n\n// Add layers accordingly\nMap.addLayer(Flooded_Areas_Unmasked, floodedAreasVis, 'Flooded Areas');\nMap.addLayer(Affected_Cropland_Unmasked, affectedCroplandVis, 'Affected Cropland');\nMap.addLayer(Affected_Builtup_Unmasked, affectedBuiltuplandVis, 'Affected Built-up');\nMap.addLayer(BuildingFootprints_Unmasked, affectedBuildingFootprintsVis, 'Affected Building Footprints');\nOn the top-left of the UI is a tool bar which enables the user to freely select the area they wish to analyse.\n// Create a drawing tool\nvar drawingTools = Map.drawingTools();\ndrawingTools.setShown(true);\nOn the right side of the map is the statistical information panel, which presents crucial data in a concise, tabulated format. This includes metrics such as affected cropland area (in hectares), affected built-up area, affected population, total flood area, and the total area under consideration. The numerical data is clearly delineated which directly answer the questions examined in this project. If the user want to choose another area, he can click the “clear” button on the bottom of the panel and repeat the process of selecting.\n// Create a panel to display the statistics and clear button\nvar panel = ui.Panel({\n  style: {\n    position: 'bottom-right',\n    width: '250px',\n    padding: '8px',\n    backgroundColor: 'white',\n    fontFamily: 'Arial',\n    fontSize: '14px'\n  }\n});\n\n// Create a title label\nvar titleLabel = ui.Label({\n  value: 'Flood Impact Statistics',\n  style: {fontWeight: 'bold', fontSize: '18px', margin: '10px 0'}\n});\n\n// Create labels to display the statistics\nvar croplandLabel = ui.Label({style: {color: '#CD8B0E', fontSize: '16px'}});\nvar buildlandLabel = ui.Label({style: {color: 'red', fontSize: '16px'}});\nvar populationLabel = ui.Label({style: {color: 'green', fontSize: '16px'}});\nvar floodAreaLabel = ui.Label({style: {color: '#415FC1', fontSize: '16px'}});\nvar totalAreaLabel = ui.Label({style: {color: '#243F81', fontSize: '16px'}});\n\n// Create a clear button\nvar clearButton = ui.Button({\n  label: 'Clear',\n  style: {backgroundColor: '#FF5722', color: 'black', fontSize: '14px', margin: '10px 0'},\n  onClick: function() {\n    drawingTools.layers().reset();\n    croplandLabel.setValue('');\n    buildlandLabel.setValue('');\n    populationLabel.setValue('');\n    floodAreaLabel.setValue('');\n    totalAreaLabel.setValue('');\n  }\n});\n\n// Add the labels and clear button to the panel\npanel.add(titleLabel);\npanel.add(ui.Label('Affected Cropland (ha):'));\npanel.add(croplandLabel);\npanel.add(ui.Label('Affected Built-up (ha):'));\npanel.add(buildlandLabel);\npanel.add(ui.Label('Affected Population:'));\npanel.add(populationLabel);\npanel.add(ui.Label('Flood Area (ha):'));\npanel.add(floodAreaLabel);\npanel.add(ui.Label('Total Area (ha):'));\npanel.add(totalAreaLabel);\npanel.add(clearButton);\nOn the left-bottom is a panel of lengend, which represents different color of the land use.\n// Create a legend panel\nvar legend = ui.Panel({\n  style: {\n    position: 'bottom-left',\n    padding: '8px'\n  }\n});\n\n// Create a legend title\nvar legendTitle = ui.Label({\n  value: 'Legend',\n  style: {fontWeight: 'bold', fontSize: '18px', margin: '0 0 4px 0'}\n});\n\nlegend.add(legendTitle);\n\n// Create a legend row\nvar makeRow = function(color, name) {\n  var colorBox = ui.Label({\n    style: {\n      backgroundColor: color,\n      padding: '8px',\n      margin: '0 0 4px 0'\n    }\n  });\n  var description = ui.Label({\n    value: name,\n    style: {margin: '0 0 4px 6px'}\n  });\n  return ui.Panel({\n    widgets: [colorBox, description],\n    layout: ui.Panel.Layout.Flow('horizontal')\n  });\n};\n\n// Add legend items\nlegend.add(makeRow('yellow', 'Affected Cropland'));\nlegend.add(makeRow('red', 'Affected Built-up'));\nlegend.add(makeRow('#415FC1', 'Flooded Areas'));\nlegend.add(makeRow('#050509', 'Affected Building Footprints'));\n\n// Add the legend to the map\nMap.add(legend);\n\nData transmission\n\nThe code loads a series of pre-generated raster images representing different aspects of the flood impact such as ‘Affected Builtup’, ‘Flooded Population’, etc. These rasters are processed to set non-valued pixels to transparent, which would allow for overlaying them on the map without obscuring other layers.\n// Load the products we generated\nvar Affected_Builtup = ee.Image('projects/ee-zhengying11140/assets/Affected_Builtup');\nvar Flooded_Population = ee.Image('projects/ee-zhengying11140/assets/Flooded_Population');\nvar Flooded_Areas = ee.Image('projects/ee-zhengying11140/assets/Flooded_Areas');\nvar Classification_Result = ee.Image('projects/ee-zhengying11140/assets/Classification_Result');\nvar Affected_Cropland = ee.Image('projects/ee-zhengying11140/assets/Affected_Cropland');\nvar BuildingFootprints = ee.Image('projects/ee-zhengying11140/assets/MaskedClassPrediction');\nWhen the user selects an area on the map, the onDraw event triggers data capture. Then, a variable aoi is returned, which represents geometry, and this variable is brought into the function calculateFloodImpactStats for calculation. The equations are encapsulated to calculate the full range of values required. When the user needs to calculate new data, just refresh the value of aoi, which is very efficient.\n// Listen for the draw end event\ndrawingTools.onDraw(function(geometry) {\n  // Get the drawn geometry\n  var aoi = geometry;\n  \n  // Display a calculating message\n  croplandLabel.setValue('Calculating...');\n  buildlandLabel.setValue('Calculating...');\n  populationLabel.setValue('Calculating...');\n  floodAreaLabel.setValue('Calculating...');\n  totalAreaLabel.setValue('Calculating...');\n  \n  // Call the calculation function and update the labels\n  var stats = calculateFloodImpactStats(Affected_Cropland, Affected_Builtup, Flooded_Population, Flooded_Areas, BuildingFootprints, 'VV', aoi);\nA function calculateFloodImpactStats is defined to compute statistics such as the area of affected cropland and built-up land in hectares, the number of affected population, and the area of flooded regions, based on the pixel values of the respective images within the selected AOI. The calculations use GEE’s reduction methods over the specified region at a defined scale.\nfunction calculateFloodImpactStats(Affected_Cropland, Affected_Builtup, Flooded_Population, Flooded_Areas, BuildingFootprints, polarization, aoi) {\n  // Calculate the area of each affected cropland pixel\n  var affectedCroplandArea = Affected_Cropland.multiply(ee.Image.pixelArea());\n\n  // Calculate the sum of the affected cropland area\n  var croplandStats = affectedCroplandArea.reduceRegion({\n    reducer: ee.Reducer.sum(),\n    geometry: aoi,\n    scale: 10, \n    maxPixels: 1e9\n  });\n\n  var croplandAreaHectares = ee.Number(croplandStats.get('b1')).divide(10000).round();\n\n  // Calculate the area of each affected built-up land pixel\n  var affectedBuildlandArea = Affected_Builtup.multiply(ee.Image.pixelArea());\n\n  // Calculate the sum of the affected built-up land area\n  var buildlandStats = affectedBuildlandArea.reduceRegion({\n    reducer: ee.Reducer.sum(),\n    geometry: aoi,\n    scale: 10,\n    maxPixels: 1e9\n  });\n\n  var buildlandAreaHectares = ee.Number(buildlandStats.get('b1')).divide(10000).round();\n\n  // Calculate the number of affected population\n  var populationStats = Flooded_Population.reduceRegion({\n    reducer: ee.Reducer.sum(),\n    geometry: aoi,\n    scale: 100,\n    maxPixels: 1e9\n  });\n\n  var affectedPopulation = ee.Number(populationStats.get('b1')).round();\n\n  // Calculate the area of flooded regions\n  var flood_pixelarea = Flooded_Areas.multiply(ee.Image.pixelArea());\n\n  var flood_stats = flood_pixelarea.reduceRegion({\n    reducer: ee.Reducer.sum(),\n    geometry: aoi,\n    scale: 10,\n    bestEffort: true\n  });\n\n  var flood_area_ha = ee.Number(flood_stats.get('b1')).divide(10000).round();\n\n\n  // Calculate the total area of the selected AOI\n  var totalArea = ee.Image.pixelArea().reduceRegion({\n    reducer: ee.Reducer.sum(),\n    geometry: aoi,\n    scale: 10,\n    maxPixels: 1e13\n  });\n\n  var totalAreaHectares = ee.Number(totalArea.get('area')).divide(10000).round();\n\n // Return an object containing all the calculated results\n  return {\n    croplandAreaHectares: croplandAreaHectares,\n    buildlandAreaHectares: buildlandAreaHectares,\n    affectedPopulation: affectedPopulation,\n    floodAreaHectares: flood_area_ha,\n    totalAreaHectares: totalAreaHectares\n  };\n}"
  },
  {
    "objectID": "index.html#link",
    "href": "index.html#link",
    "title": "Al Marj Flood Impact Comprehensive Evaluation System",
    "section": "",
    "text": "Github For the Application\nApplication\nApplication code\nUI code"
  }
]